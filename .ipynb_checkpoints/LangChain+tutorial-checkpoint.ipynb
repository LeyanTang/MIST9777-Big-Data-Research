{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b42ab-68d6-4c22-bf50-c9b9a169f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69a91e6-a00b-4646-92f1-f6a3fed7c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee373079-e4fd-4742-8690-5174180c97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "YOUR_GITHUB_PERSONAL_TOKEN ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "ACCESS_TOKEN = getpass(\"YOUR_GITHUB_PERSONAL_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb218263-cdf5-4795-8d38-d8c5da936784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import GitHubIssuesLoader\n",
    "\n",
    "loader = GitHubIssuesLoader(repo=\"huggingface/peft\", access_token=ACCESS_TOKEN, include_prs=False, state=\"all\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63719b60-79ed-4b5a-ac22-399b950adf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
    "\n",
    "chunked_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8932d71-a4dc-46f2-8a0e-0ba797f1149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/khnp93wx4ws93_vyzb_jb9mh0000gn/T/ipykernel_35521/965698010.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  db = FAISS.from_documents(chunked_docs, HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "db = FAISS.from_documents(chunked_docs, HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7188709a-dffc-45da-9d6c-867971a6bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cfe57a5-6d8d-49d9-9208-01068c87d488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a91b3f1ed14132822fb7abfcb931f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "# Load model with Metal-compatible settings\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,  # Use float16 instead of 4-bit quantization\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d34aefc-3410-48f1-90f0-3f432d9a7873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/var/folders/qp/khnp93wx4ws93_vyzb_jb9mh0000gn/T/ipykernel_35521/2304814980.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=400,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "Answer the question based on your knowledge. Use the following context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9cb3626-707f-461b-97eb-31d842534d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93134562-122d-4aab-a361-5e3dfa0ab330",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do you combine multiple adapters?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677e20b7-a20a-4f10-a3fe-4414dde04677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n<|system|>\\nAnswer the question based on your knowledge. Use the following context to help:\\n\\n\\n\\n</s>\\n<|user|>\\nHow do you combine multiple adapters?\\n</s>\\n<|assistant|>\\n\\n  To combine multiple adapters, you need to ensure that they are compatible with each other and with the device you want to connect. Here's how you can do it:\\n\\n1. Identify the devices you want to connect: Determine which devices you want to connect using the adapters. For example, you might want to connect a USB-C laptop to an HDMI monitor or a VGA projector.\\n\\n2. Choose the right adapters: Look for adapters that convert the output of your laptop (USB-C, HDMI, or DisplayPort) into the input format required by your monitor or projector (VGA, DVI, or HDMI). Make sure the adapters are compatible with both your laptop and the display device.\\n\\n3. Connect the adapters: Plug one adapter into your laptop, then connect another adapter to it if necessary. Continue connecting adapters until you reach the final device you want to connect.\\n\\n4. Test the connection: Turn on your laptop and the connected device to make sure everything is working properly. If you encounter any issues, try rearranging the order of the adapters or checking their compatibility.\\n\\n5. Manage power: Some adapters may require additional power sources, such as a USB hub or a separate power supply. Make sure you have enough power to support all the connected devices.\\n\\nRemember to always follow the manufacturer's instructions when using adapters, and be careful not to overload your laptop's ports or power supply. By combining multiple adapters, you can expand the capabilities of your laptop and connect to a wider range of devices.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\": \"\", \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1255c893-d8ff-48d6-b7ea-f962c73de3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<|system|>\\nAnswer the question based on your knowledge. Use the following context to help:\\n\\n[Document(id=\\'5df08550-5c9f-412f-af9f-9a09386ab6a2\\', metadata={\\'url\\': \\'https://github.com/huggingface/peft/issues/1802\\', \\'title\\': \\'Issues when switching between multiple adapters LoRAs \\', \\'creator\\': \\'JhonDan1999\\', \\'created_at\\': \\'2024-05-26T19:18:13Z\\', \\'comments\\': 8, \\'state\\': \\'closed\\', \\'labels\\': [], \\'assignee\\': None, \\'milestone\\': None, \\'locked\\': False, \\'number\\': 1802, \\'is_pull_request\\': False}, page_content=\\'The documentation does not mention the need to perform a merge when switching adapters. Additionally, the methods add_adapter, set_adapter, and enable_adapters do not appear to work\\\\r\\\\n\\\\r\\\\nPlease provide clarification on how to correctly switch between adapters\\'), Document(id=\\'027e9c64-40b5-48c4-a39d-ac2f5d9294e6\\', metadata={\\'url\\': \\'https://github.com/huggingface/peft/issues/1045\\', \\'title\\': \\'add_weighted_adapter() is unusable, throws error: \"Invalid type <class \\\\\\'list\\\\\\'> found in target_modules\"\\', \\'creator\\': \\'Vectorrent\\', \\'created_at\\': \\'2023-10-22T21:42:32Z\\', \\'comments\\': 6, \\'state\\': \\'closed\\', \\'labels\\': [], \\'assignee\\': None, \\'milestone\\': None, \\'locked\\': False, \\'number\\': 1045, \\'is_pull_request\\': False}, page_content=\"If you can provide any advice, I would greatly appreciate it. I suspect that this is either unsupported and/or not fully-implemented; or, it has something to do with the way I\\'m attaching adapters. I\\'ve tried a bunch of alternate configurations, but I\\'m not having luck.\\\\r\\\\n\\\\r\\\\nThanks in advance for any help you might provide.\"), Document(id=\\'64ab4d6f-1908-41dc-907f-a45a6a4666a1\\', metadata={\\'url\\': \\'https://github.com/huggingface/peft/issues/1497\\', \\'title\\': \\'Cannot load adapters from Peft.from_pretrained\\', \\'creator\\': \\'dame-cell\\', \\'created_at\\': \\'2024-02-21T13:37:31Z\\', \\'comments\\': 0, \\'state\\': \\'closed\\', \\'labels\\': [], \\'assignee\\': None, \\'milestone\\': None, \\'locked\\': False, \\'number\\': 1497, \\'is_pull_request\\': False}, page_content=\\'### Expected behavior\\\\r\\\\n\\\\r\\\\nI think I would want the adapters to be downloaded and then I would be able to merge my adapters into one\\'), Document(id=\\'955c6711-bee1-428e-b14e-8d9cfb62c8f4\\', metadata={\\'url\\': \\'https://github.com/huggingface/peft/issues/1434\\', \\'title\\': \\'Running multiple adapters simultaneously, reusing the output from the base model\\', \\'creator\\': \\'sachin-patel-qp\\', \\'created_at\\': \\'2024-02-05T11:56:15Z\\', \\'comments\\': 4, \\'state\\': \\'closed\\', \\'labels\\': [], \\'assignee\\': None, \\'milestone\\': None, \\'locked\\': False, \\'number\\': 1434, \\'is_pull_request\\': False}, page_content=\"I\\'m new to the concept of adapters and had a question: Is it possible to run multiple adapters simultaneously while reusing the output from the base model?\\\\r\\\\n\\\\r\\\\nFor instance, consider a base model named Base_model and 2 adapters, Adapter_1 and Adapter_2. \\\\r\\\\nCurrently, to obtain outputs from these two different adapters, we need to load and run them separately:\\\\r\\\\n\\\\r\\\\n1. Base_model --> Adapter_1 ---> Output_1\\\\r\\\\n2. Base_model --> Adapter_2 ---> Output_2\")]\\n\\n</s>\\n<|user|>\\nHow do you combine multiple adapters?\\n</s>\\n<|assistant|>\\n\\n  To combine multiple adapters using PyTorch-based framework PEFT (Python Extension for Transformers), you can follow these steps:\\n\\n1. Load the base model and the individual adapters using `Peft` class.\\n\\n   ```python\\n   from peft import Peft\\n   \\n   # Load the base model\\n   base_model = AutoModelForSequenceClassification.from_pretrained(\\'base_model\\')\\n   \\n   # Load adapter 1\\n   adapter_1 = AutoAdapterForSequenceClassification.from_pretrained(\\'adapter_1\\')\\n   \\n   # Load adapter 2\\n   adapter_2 = AutoAdapterForSequenceClassification.from_pretrained(\\'adapter_2\\')\\n   ```\\n\\n2. Wrap the base model with the first adapter using the `wrap_model` method provided by PEFT. This will replace the last few layers of the base model with the adapter.\\n\\n   ```python\\n   wrapped_model = adapter_1.wrap_model(base_model)\\n   ```\\n\\n3. Freeze the weights of the adapter and the base model using the `freeze_weights` method provided by PEFT. This ensures that the weights of the adapter and the base model are not updated during training.\\n\\n   ```python\\n   adapter_1.freeze_weights()\\n   wrapped_model.freeze_weights()\\n   ```\\n\\n4. Wrap the second adapter around the wrapped model using the `wrap_model` method again. This will replace the last few layers of the wrapped model with the second adapter.\\n\\n   ```python\\n   wrapped_wrapped_model = adapter_2.wrap_model(wrapped_model)\\n   ```\\n\\n5. Freeze the weights of the second adapter as well.\\n\\n   ```python\\n   adapter_2.free'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf0206-f6eb-46ce-8be4-41f4030539b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
